<!DOCTYPE html>
<html lang="en"><head>
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.5.1/jquery.min.js" integrity="sha512-bLT0Qm9VnAYZDflyKcBaQ2gg0hSYNQrJ8RilYldYQ1FxQYoCLtUjuuRuZo+fjqhx/qtq/1itJ0C2ejDxltZVFg==" crossorigin="anonymous"></script><script src="../site_libs/clipboard/clipboard.min.js"></script>
<script src="../site_libs/quarto-html/tabby.min.js"></script>
<script src="../site_libs/quarto-html/popper.min.js"></script>
<script src="../site_libs/quarto-html/tippy.umd.min.js"></script>
<link href="../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../site_libs/quarto-html/light-border.css" rel="stylesheet">
<link href="../site_libs/quarto-html/quarto-syntax-highlighting-2f5df379a58b258e96c21c0638c20c03.css" rel="stylesheet" id="quarto-text-highlighting-styles"><meta charset="utf-8">
  <meta name="generator" content="quarto-1.6.42">

  <meta name="author" content="Alan R. Vazquez">
  <title>IN2004B Generation of Value with Data Analytics – Ensemble Methods for Regression</title>
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">
  <link rel="stylesheet" href="../site_libs/revealjs/dist/reset.css">
  <link rel="stylesheet" href="../site_libs/revealjs/dist/reveal.css">
  <style>
    code{white-space: pre-wrap;}
    span.smallcaps{font-variant: small-caps;}
    div.columns{display: flex; gap: min(4vw, 1.5em);}
    div.column{flex: auto; overflow-x: auto;}
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
    ul.task-list{list-style: none;}
    ul.task-list li input[type="checkbox"] {
      width: 0.8em;
      margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
      vertical-align: middle;
    }
    /* CSS for syntax highlighting */
    pre > code.sourceCode { white-space: pre; position: relative; }
    pre > code.sourceCode > span { line-height: 1.25; }
    pre > code.sourceCode > span:empty { height: 1.2em; }
    .sourceCode { overflow: visible; }
    code.sourceCode > span { color: inherit; text-decoration: inherit; }
    div.sourceCode { margin: 1em 0; }
    pre.sourceCode { margin: 0; }
    @media screen {
    div.sourceCode { overflow: auto; }
    }
    @media print {
    pre > code.sourceCode { white-space: pre-wrap; }
    pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
    }
    pre.numberSource code
      { counter-reset: source-line 0; }
    pre.numberSource code > span
      { position: relative; left: -4em; counter-increment: source-line; }
    pre.numberSource code > span > a:first-child::before
      { content: counter(source-line);
        position: relative; left: -1em; text-align: right; vertical-align: baseline;
        border: none; display: inline-block;
        -webkit-touch-callout: none; -webkit-user-select: none;
        -khtml-user-select: none; -moz-user-select: none;
        -ms-user-select: none; user-select: none;
        padding: 0 4px; width: 4em;
        color: #aaaaaa;
      }
    pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
    div.sourceCode
      { color: #003b4f; background-color: #f1f3f5; }
    @media screen {
    pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
    }
    code span { color: #003b4f; } /* Normal */
    code span.al { color: #ad0000; } /* Alert */
    code span.an { color: #5e5e5e; } /* Annotation */
    code span.at { color: #657422; } /* Attribute */
    code span.bn { color: #ad0000; } /* BaseN */
    code span.bu { } /* BuiltIn */
    code span.cf { color: #003b4f; font-weight: bold; } /* ControlFlow */
    code span.ch { color: #20794d; } /* Char */
    code span.cn { color: #8f5902; } /* Constant */
    code span.co { color: #5e5e5e; } /* Comment */
    code span.cv { color: #5e5e5e; font-style: italic; } /* CommentVar */
    code span.do { color: #5e5e5e; font-style: italic; } /* Documentation */
    code span.dt { color: #ad0000; } /* DataType */
    code span.dv { color: #ad0000; } /* DecVal */
    code span.er { color: #ad0000; } /* Error */
    code span.ex { } /* Extension */
    code span.fl { color: #ad0000; } /* Float */
    code span.fu { color: #4758ab; } /* Function */
    code span.im { color: #00769e; } /* Import */
    code span.in { color: #5e5e5e; } /* Information */
    code span.kw { color: #003b4f; font-weight: bold; } /* Keyword */
    code span.op { color: #5e5e5e; } /* Operator */
    code span.ot { color: #003b4f; } /* Other */
    code span.pp { color: #ad0000; } /* Preprocessor */
    code span.sc { color: #5e5e5e; } /* SpecialChar */
    code span.ss { color: #20794d; } /* SpecialString */
    code span.st { color: #20794d; } /* String */
    code span.va { color: #111111; } /* Variable */
    code span.vs { color: #20794d; } /* VerbatimString */
    code span.wa { color: #5e5e5e; font-style: italic; } /* Warning */
  </style>
  <link rel="stylesheet" href="../site_libs/revealjs/dist/theme/quarto-2f366650f320edcfcf53d73c80250a32.css">
  <link rel="stylesheet" href="style.css">
  <link href="../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.css" rel="stylesheet">
  <link href="../site_libs/revealjs/plugin/reveal-menu/menu.css" rel="stylesheet">
  <link href="../site_libs/revealjs/plugin/reveal-menu/quarto-menu.css" rel="stylesheet">
  <link href="../site_libs/revealjs/plugin/quarto-support/footer.css" rel="stylesheet">
  <style type="text/css">
    .reveal div.sourceCode {
      margin: 0;
      overflow: auto;
    }
    .reveal div.hanging-indent {
      margin-left: 1em;
      text-indent: -1em;
    }
    .reveal .slide:not(.center) {
      height: 100%;
    }
    .reveal .slide.scrollable {
      overflow-y: auto;
    }
    .reveal .footnotes {
      height: 100%;
      overflow-y: auto;
    }
    .reveal .slide .absolute {
      position: absolute;
      display: block;
    }
    .reveal .footnotes ol {
      counter-reset: ol;
      list-style-type: none; 
      margin-left: 0;
    }
    .reveal .footnotes ol li:before {
      counter-increment: ol;
      content: counter(ol) ". "; 
    }
    .reveal .footnotes ol li > p:first-child {
      display: inline-block;
    }
    .reveal .slide ul,
    .reveal .slide ol {
      margin-bottom: 0.5em;
    }
    .reveal .slide ul li,
    .reveal .slide ol li {
      margin-top: 0.4em;
      margin-bottom: 0.2em;
    }
    .reveal .slide ul[role="tablist"] li {
      margin-bottom: 0;
    }
    .reveal .slide ul li > *:first-child,
    .reveal .slide ol li > *:first-child {
      margin-block-start: 0;
    }
    .reveal .slide ul li > *:last-child,
    .reveal .slide ol li > *:last-child {
      margin-block-end: 0;
    }
    .reveal .slide .columns:nth-child(3) {
      margin-block-start: 0.8em;
    }
    .reveal blockquote {
      box-shadow: none;
    }
    .reveal .tippy-content>* {
      margin-top: 0.2em;
      margin-bottom: 0.7em;
    }
    .reveal .tippy-content>*:last-child {
      margin-bottom: 0.2em;
    }
    .reveal .slide > img.stretch.quarto-figure-center,
    .reveal .slide > img.r-stretch.quarto-figure-center {
      display: block;
      margin-left: auto;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-left,
    .reveal .slide > img.r-stretch.quarto-figure-left  {
      display: block;
      margin-left: 0;
      margin-right: auto; 
    }
    .reveal .slide > img.stretch.quarto-figure-right,
    .reveal .slide > img.r-stretch.quarto-figure-right  {
      display: block;
      margin-left: auto;
      margin-right: 0; 
    }
  </style>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" integrity="sha512-c3Nl8+7g4LMSTdrm621y7kf9v3SDPnhxLNhcjFJbKECVnmZHTdo+IRO05sNLTH/D3vA6u1X32ehoLC7WFVdheg==" crossorigin="anonymous"></script>
  
  <script type="application/javascript">define('jquery', [],function() {return window.jQuery;})</script>
</head>
<body class="quarto-light">
  <div class="reveal">
    <div class="slides">

<section id="title-slide" class="quarto-title-block center">
  <h1 class="title">Ensemble Methods for Regression</h1>
  <p class="subtitle">IN2004B: Generation of Value with Data Analytics</p>

<div class="quarto-title-authors">
<div class="quarto-title-author">
<div class="quarto-title-author-name">
Alan R. Vazquez 
</div>
        <p class="quarto-title-affiliation">
            Department of Industrial Engineering
          </p>
    </div>
</div>

</section>
<section id="agenda" class="slide level2">
<h2>Agenda</h2>
<p><br></p>
<ol type="1">
<li>Introduction</li>
<li>Bagging</li>
<li>Random Forests</li>
<li>Boosting</li>
<li>Ensemble Methods for Time Series</li>
</ol>
</section>
<section>
<section id="introduction" class="title-slide slide level1 center">
<h1>Introduction</h1>

</section>
<section id="load-the-libraries" class="slide level2">
<h2>Load the libraries</h2>
<p><br></p>
<p>Before we start, let’s import the data science libraries into Python.</p>
<div id="9c200203" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-2"><a></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-3"><a></a><span class="im">import</span> seaborn <span class="im">as</span> sns</span>
<span id="cb1-4"><a></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split, TimeSeriesSplit</span>
<span id="cb1-5"><a></a><span class="im">from</span> sklearn.tree <span class="im">import</span> DecisionTreeRegressor, plot_tree</span>
<span id="cb1-6"><a></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> BaggingRegressor, RandomForestRegressor</span>
<span id="cb1-7"><a></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span>  GradientBoostingRegressor</span>
<span id="cb1-8"><a></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> mean_squared_error</span>
<span id="cb1-9"><a></a><span class="im">from</span> sklearn.inspection <span class="im">import</span> permutation_importance</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Here, we use specific functions from the <strong>pandas</strong>, <strong>matplotlib</strong>, <strong>seaborn</strong> and <strong>sklearn</strong> libraries in Python.</p>
</section>
<section id="decision-trees" class="slide level2">
<h2>Decision trees</h2>
<p><br></p>
<div class="columns">
<div class="column" style="width:45%;">
<div style="font-size: 90%;">
<ul>
<li><p>Simple and useful for interpretations.</p></li>
<li><p>Can handle continuous and categorical predictors and responses. So, they can be applied to both <span style="color:blue;"><strong>classification</strong></span> and <span style="color:green;"><strong>regression</strong></span> problems.</p></li>
<li><p>Computationally efficient.</p></li>
</ul>
</div>
</div><div class="column" style="width:55%;">
<p><br></p>
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="images/clipboard-2280895928.png" class="quarto-figure quarto-figure-center"></p>
</figure>
</div>
</div></div>
</section>
<section id="decision-trees-for-regression" class="slide level2">
<h2>Decision trees for regression</h2>
<p><br><br></p>
<ul>
<li><p>The procedure for constructing a decision tree for regression is the same as for a classification tree.</p></li>
<li><p>That is, we use the CART algorithm for building large trees and cost complexity pruning to reduce them, if desired.</p></li>
<li><p>However, instead of using impurity to evaluate splits, we use the mean squared error.</p></li>
</ul>
</section>
<section id="section" class="slide level2">
<h2></h2>
<p><br><br></p>
<p>To compute the mean squared error we use</p>
<ul>
<li><p>The predicted response is the average response calculated in the node or region.</p></li>
<li><p>The actual responses are those of the observations in the region.</p></li>
</ul>
<p>We refer to decision trees for regression as <strong>regression trees</strong>.</p>
</section>
<section id="example-1" class="slide level2">
<h2>Example 1</h2>
<p>The “Hitters.xlsx” dataset contains data collected from Major League Baseball players. It includes data on various statistics such as number of hits, years in the league, and salary. The <strong>goal</strong> is to predict a player’s salary based on performance statistics.</p>
<div style="font-size: 90%;">
<p>The <span style="color:darkred;">response</span> is the player’s salary (in $), contained in the column <code>Salary</code>.</p>
<p>For this example, we will focus on two predictors:</p>
<ul>
<li><code>Hits</code>: Number of hits in the season<br>
</li>
<li><code>Years</code>: Number of years the player has been in the league</li>
</ul>
</div>
</section>
<section id="read-the-dataset" class="slide level2">
<h2>Read the dataset</h2>
<p>We read the dataset</p>
<div id="54cd00e2" class="cell" data-execution_count="2">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a></a>Hitters_data <span class="op">=</span> pd.read_excel(<span class="st">'Hitters.xlsx'</span>)</span>
<span id="cb2-2"><a></a>Hitters_data.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="2">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe caption-top" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header" style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">AtBat</th>
<th data-quarto-table-cell-role="th">Hits</th>
<th data-quarto-table-cell-role="th">HmRun</th>
<th data-quarto-table-cell-role="th">Runs</th>
<th data-quarto-table-cell-role="th">RBI</th>
<th data-quarto-table-cell-role="th">Walks</th>
<th data-quarto-table-cell-role="th">Years</th>
<th data-quarto-table-cell-role="th">CAtBat</th>
<th data-quarto-table-cell-role="th">CHits</th>
<th data-quarto-table-cell-role="th">CHmRun</th>
<th data-quarto-table-cell-role="th">CRuns</th>
<th data-quarto-table-cell-role="th">CRBI</th>
<th data-quarto-table-cell-role="th">CWalks</th>
<th data-quarto-table-cell-role="th">League</th>
<th data-quarto-table-cell-role="th">Division</th>
<th data-quarto-table-cell-role="th">PutOuts</th>
<th data-quarto-table-cell-role="th">Assists</th>
<th data-quarto-table-cell-role="th">Errors</th>
<th data-quarto-table-cell-role="th">Salary</th>
<th data-quarto-table-cell-role="th">NewLeague</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>293</td>
<td>66</td>
<td>1</td>
<td>30</td>
<td>29</td>
<td>14</td>
<td>1</td>
<td>293</td>
<td>66</td>
<td>1</td>
<td>30</td>
<td>29</td>
<td>14</td>
<td>A</td>
<td>E</td>
<td>446</td>
<td>33</td>
<td>20</td>
<td>NaN</td>
<td>A</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>315</td>
<td>81</td>
<td>7</td>
<td>24</td>
<td>38</td>
<td>39</td>
<td>14</td>
<td>3449</td>
<td>835</td>
<td>69</td>
<td>321</td>
<td>414</td>
<td>375</td>
<td>N</td>
<td>W</td>
<td>632</td>
<td>43</td>
<td>10</td>
<td>475.0</td>
<td>N</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>479</td>
<td>130</td>
<td>18</td>
<td>66</td>
<td>72</td>
<td>76</td>
<td>3</td>
<td>1624</td>
<td>457</td>
<td>63</td>
<td>224</td>
<td>266</td>
<td>263</td>
<td>A</td>
<td>W</td>
<td>880</td>
<td>82</td>
<td>14</td>
<td>480.0</td>
<td>A</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>496</td>
<td>141</td>
<td>20</td>
<td>65</td>
<td>78</td>
<td>37</td>
<td>11</td>
<td>5628</td>
<td>1575</td>
<td>225</td>
<td>828</td>
<td>838</td>
<td>354</td>
<td>N</td>
<td>E</td>
<td>200</td>
<td>11</td>
<td>3</td>
<td>500.0</td>
<td>N</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>321</td>
<td>87</td>
<td>10</td>
<td>39</td>
<td>42</td>
<td>30</td>
<td>2</td>
<td>396</td>
<td>101</td>
<td>12</td>
<td>48</td>
<td>46</td>
<td>33</td>
<td>N</td>
<td>E</td>
<td>805</td>
<td>40</td>
<td>4</td>
<td>91.5</td>
<td>N</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</section>
<section id="section-1" class="slide level2">
<h2></h2>
<p>The data set has some missing observations. So, we remove the observations with at least one missing value in a predictor.</p>
<div id="c893bcb1" class="cell" data-execution_count="3">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a></a>Hitters_data_clean <span class="op">=</span> Hitters_data.dropna()</span>
<span id="cb3-2"><a></a>Hitters_data_clean.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="3">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe caption-top" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header" style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">AtBat</th>
<th data-quarto-table-cell-role="th">Hits</th>
<th data-quarto-table-cell-role="th">HmRun</th>
<th data-quarto-table-cell-role="th">Runs</th>
<th data-quarto-table-cell-role="th">RBI</th>
<th data-quarto-table-cell-role="th">Walks</th>
<th data-quarto-table-cell-role="th">Years</th>
<th data-quarto-table-cell-role="th">CAtBat</th>
<th data-quarto-table-cell-role="th">CHits</th>
<th data-quarto-table-cell-role="th">CHmRun</th>
<th data-quarto-table-cell-role="th">CRuns</th>
<th data-quarto-table-cell-role="th">CRBI</th>
<th data-quarto-table-cell-role="th">CWalks</th>
<th data-quarto-table-cell-role="th">League</th>
<th data-quarto-table-cell-role="th">Division</th>
<th data-quarto-table-cell-role="th">PutOuts</th>
<th data-quarto-table-cell-role="th">Assists</th>
<th data-quarto-table-cell-role="th">Errors</th>
<th data-quarto-table-cell-role="th">Salary</th>
<th data-quarto-table-cell-role="th">NewLeague</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">1</td>
<td>315</td>
<td>81</td>
<td>7</td>
<td>24</td>
<td>38</td>
<td>39</td>
<td>14</td>
<td>3449</td>
<td>835</td>
<td>69</td>
<td>321</td>
<td>414</td>
<td>375</td>
<td>N</td>
<td>W</td>
<td>632</td>
<td>43</td>
<td>10</td>
<td>475.0</td>
<td>N</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">2</td>
<td>479</td>
<td>130</td>
<td>18</td>
<td>66</td>
<td>72</td>
<td>76</td>
<td>3</td>
<td>1624</td>
<td>457</td>
<td>63</td>
<td>224</td>
<td>266</td>
<td>263</td>
<td>A</td>
<td>W</td>
<td>880</td>
<td>82</td>
<td>14</td>
<td>480.0</td>
<td>A</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">3</td>
<td>496</td>
<td>141</td>
<td>20</td>
<td>65</td>
<td>78</td>
<td>37</td>
<td>11</td>
<td>5628</td>
<td>1575</td>
<td>225</td>
<td>828</td>
<td>838</td>
<td>354</td>
<td>N</td>
<td>E</td>
<td>200</td>
<td>11</td>
<td>3</td>
<td>500.0</td>
<td>N</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">4</td>
<td>321</td>
<td>87</td>
<td>10</td>
<td>39</td>
<td>42</td>
<td>30</td>
<td>2</td>
<td>396</td>
<td>101</td>
<td>12</td>
<td>48</td>
<td>46</td>
<td>33</td>
<td>N</td>
<td>E</td>
<td>805</td>
<td>40</td>
<td>4</td>
<td>91.5</td>
<td>N</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">5</td>
<td>594</td>
<td>169</td>
<td>4</td>
<td>74</td>
<td>51</td>
<td>35</td>
<td>11</td>
<td>4408</td>
<td>1133</td>
<td>19</td>
<td>501</td>
<td>336</td>
<td>194</td>
<td>A</td>
<td>W</td>
<td>282</td>
<td>421</td>
<td>25</td>
<td>750.0</td>
<td>A</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</section>
<section id="generating-training-and-validation-data" class="slide level2">
<h2>Generating training and validation data</h2>
<p><br></p>
<p>Select the predictors and response</p>
<div id="3c7cbe6d" class="cell" data-execution_count="4">
<div class="sourceCode cell-code" id="cb4"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a></a>X_full <span class="op">=</span> Hitters_data_clean.<span class="bu">filter</span>([<span class="st">"Years"</span>, <span class="st">"Hits"</span>])</span>
<span id="cb4-2"><a></a>Y_full <span class="op">=</span> Hitters_data_clean.<span class="bu">filter</span>([<span class="st">"Salary"</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><br></p>
<p>We partition the full dataset into 70% for training and the other 30% for validation.</p>
<div id="6f17ee93" class="cell" data-execution_count="5">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a></a><span class="co"># Split the dataset into training and validation.</span></span>
<span id="cb5-2"><a></a>X_train, X_valid, Y_train, Y_valid <span class="op">=</span> train_test_split(X_full, Y_full, </span>
<span id="cb5-3"><a></a>                                                      test_size <span class="op">=</span> <span class="fl">0.3</span>,</span>
<span id="cb5-4"><a></a>                                                      random_state <span class="op">=</span> <span class="dv">507134</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="regression-trees-in-python" class="slide level2">
<h2>Regression trees in Python</h2>
<p><br><br></p>
<p>We train a regression tree using the <code>DecisionTreeRegressor()</code> function from regression.</p>
<div id="1d0381af" class="cell" data-execution_count="6">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a></a><span class="co"># We tell Python we want a regression tree</span></span>
<span id="cb6-2"><a></a>reg_tree <span class="op">=</span> DecisionTreeRegressor(min_samples_leaf <span class="op">=</span> <span class="dv">5</span>, max_depth<span class="op">=</span><span class="dv">3</span>, </span>
<span id="cb6-3"><a></a>                              random_state<span class="op">=</span><span class="dv">507134</span>)</span>
<span id="cb6-4"><a></a></span>
<span id="cb6-5"><a></a><span class="co"># We train the regression tree using the training data.</span></span>
<span id="cb6-6"><a></a>reg_tree.fit(X_train, Y_train)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>We use <code>max_depth = 3</code> to have a small tree as an example.</p>
</section>
<section id="plotting-the-tree" class="slide level2">
<h2>Plotting the tree</h2>
<p><br></p>
<p>To see the decision tree, we use the <code>plot_tree</code> function from <strong>scikit-learn</strong> and some commands from <strong>matplotlib</strong>.</p>
<div id="409e90c3" class="cell" data-execution_count="7">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">6</span>, <span class="dv">6</span>))</span>
<span id="cb7-2"><a></a>plot_tree(reg_tree, feature_names <span class="op">=</span> X_train.columns, filled<span class="op">=</span><span class="va">True</span>, </span>
<span id="cb7-3"><a></a>          rounded<span class="op">=</span><span class="va">True</span>)</span>
<span id="cb7-4"><a></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="section-2" class="slide level2">
<h2></h2>
<p><br></p>
<div id="a2d13402" class="cell" data-execution_count="8">
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="Nonparametric_files/figure-revealjs/cell-9-output-1.png" class="quarto-figure quarto-figure-center" width="1061" height="537"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="visualize-the-regions" class="slide level2">
<h2>Visualize the regions</h2>
<div id="1ed62558" class="cell" data-execution_count="9">
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="Nonparametric_files/figure-revealjs/cell-10-output-1.png" class="quarto-figure quarto-figure-center" width="560" height="560"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="visualize-the-predictions" class="slide level2">
<h2>Visualize the predictions</h2>
<p>We predict with the average response (<span class="math inline">\(Y\)</span>) of the observations in each region.</p>
<div id="ec1a6364" class="cell" data-execution_count="10">
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="Nonparametric_files/figure-revealjs/cell-11-output-1.png" class="quarto-figure quarto-figure-center" width="464" height="464"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="predictions-on-the-validation-data" class="slide level2">
<h2>Predictions on the validation data</h2>
<p>To predict the responses on the validation data, we use the function <code>.predict()</code> using the predictor values in the validation dataset contained in <code>X_valid</code>.</p>
<div id="f3e09752" class="cell" data-execution_count="11">
<div class="sourceCode cell-code" id="cb8"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb8-1"><a></a>Y_pred <span class="op">=</span> reg_tree.predict(X_valid)</span>
<span id="cb8-2"><a></a>Y_pred</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="11">
<pre><code>array([ 917.80951163,  601.96761111,  286.9375    ,  286.9375    ,
        286.9375    ,  140.04411765,  917.80951163,  371.67336   ,
        917.80951163,  917.80951163,  286.9375    ,  140.04411765,
        286.9375    ,  140.04411765,  140.04411765,  601.96761111,
        917.80951163,  371.67336   ,  917.80951163,  917.80951163,
       1190.42853846,  233.33333333,  286.9375    ,  140.04411765,
        917.80951163,  917.80951163,  233.33333333,  917.80951163,
        140.04411765,  140.04411765,  140.04411765,  601.96761111,
        601.96761111, 1190.42853846,  917.80951163,  233.33333333,
        371.67336   ,  371.67336   ,  286.9375    ,  601.96761111,
        917.80951163, 1190.42853846,  601.96761111,  371.67336   ,
        917.80951163, 1190.42853846,  233.33333333,  917.80951163,
        601.96761111, 1190.42853846,  917.80951163,  371.67336   ,
       1190.42853846,  233.33333333,  917.80951163,  286.9375    ,
        601.96761111,  371.67336   ,  233.33333333,  140.04411765,
        233.33333333,  140.04411765,  917.80951163,  371.67336   ,
       1190.42853846,  917.80951163,  917.80951163,  917.80951163,
        917.80951163,  140.04411765,  286.9375    ,  917.80951163,
        601.96761111,  140.04411765,  601.96761111,  601.96761111,
        601.96761111,  601.96761111,  917.80951163])</code></pre>
</div>
</div>
</section>
<section id="validation-rmse" class="slide level2">
<h2>Validation RMSE</h2>
<p><br><br></p>
<p>Recall that the responses from the validation dataset are in <code>Y_valid</code>, and the model predictions are in <code>Y_pred</code>. We compute the <em>root mean squared error</em> on the validation data using the <code>mse()</code> function.</p>
<div id="cee77a30" class="cell" data-execution_count="12">
<div class="sourceCode cell-code" id="cb10"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb10-1"><a></a>mse <span class="op">=</span> mean_squared_error(Y_valid, Y_pred)  <span class="co"># Mean Squared Error (MSE)</span></span>
<span id="cb10-2"><a></a><span class="bu">print</span>(<span class="bu">round</span>(mse<span class="op">**</span>(<span class="dv">1</span><span class="op">/</span><span class="dv">2</span>), <span class="dv">2</span>)) <span class="co"># RMSE</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>399.49</code></pre>
</div>
</div>
</section>
<section id="limitations-of-decision-trees" class="slide level2">
<h2>Limitations of decision trees</h2>
<p><br><br><br></p>
<ul>
<li><p>In general, decision trees do not work well for classification and regression problems.</p></li>
<li><p>However, they can be combined to build effective algorithms for these problems.</p></li>
</ul>
</section>
<section id="ensamble-methods" class="slide level2">
<h2>Ensamble methods</h2>
<p><br><br></p>
<p>Ensemble methods are frameworks to combine decision trees.</p>
<p>Here, we will cover two popular ensamble methods:</p>
<ul>
<li><p><span style="color:purple;"><strong>Bagging</strong></span>. Ensemble many deep trees.</p>
<ul>
<li>Quintessential method: <span style="color:purple;">Random Forests</span>.</li>
</ul></li>
<li><p><span style="color:brown;"><strong>Boosting</strong></span>. Ensemble small trees sequentially.</p></li>
</ul>
</section></section>
<section>
<section id="bagging" class="title-slide slide level1 center">
<h1>Bagging</h1>

</section>
<section id="bootstrap-samples" class="slide level2">
<h2>Bootstrap samples</h2>
<div style="font-size: 90%;">
<p>Bootstrap samples are samples obtained <em>with replacement</em> from the original sample. So, an observation can occur more than one in a bootstrap sample.</p>
<p>Bootstrap samples are the building block of the bootstrap method, which is a statistical technique for estimating quantities about a population by averaging estimates from multiple small data samples.</p>
</div>

<img data-src="images/clipboard-2003681619.png" class="quarto-figure quarto-figure-center r-stretch"></section>
<section id="bagging-1" class="slide level2">
<h2>Bagging</h2>
<p>Given a training dataset, <span style="color:purple;"><strong>bagging</strong></span> averages the predictions from decision trees over a collection of <strong><em>bootstrap</em></strong> samples.</p>

<img data-src="images/bagging_scheme.png" class="quarto-figure quarto-figure-center r-stretch"></section>
<section id="predictions" class="slide level2">
<h2>Predictions</h2>
<p>Let <span class="math inline">\(\boldsymbol{x} = (x_1, x_2, \ldots, x_p)\)</span> be a vector of new predictor values.</p>
<p>For <span style="color:darkgreen;"><strong>regression</strong></span> problems:</p>
<ol type="1">
<li><p>Each regression tree outputs the average value depending on the region <span class="math inline">\(\boldsymbol{x}\)</span> falls in. For the b-th tree, denote such average as <span class="math inline">\(\hat{T}_{b}(\boldsymbol{x})\)</span>.</p></li>
<li><p>Predict using the average of all regression trees</p></li>
</ol>
<p><span class="math display">\[\hat{f}_{bag}(\boldsymbol{x}) = \frac{1}{B} \sum_{b=1}^{B} \hat{T}_{b}(\boldsymbol{x}).  \]</span></p>
</section>
<section id="implementation" class="slide level2">
<h2>Implementation</h2>
<p><br><br></p>
<div>
<ul>
<li class="fragment"><p>How many trees? No risk of overfitting, so use plenty.</p></li>
<li class="fragment"><p>No pruning necessary to build the trees. However, one can still decide to apply some pruning or early stopping mechanism.</p></li>
<li class="fragment"><p>The size of bootstrap samples is the same as the size of the training dataset, but we can use a different size.</p></li>
</ul>
</div>
</section>
<section id="example-2" class="slide level2">
<h2>Example 2</h2>
<p><br></p>
<p>The “BostonHousing.xlsx” contains data collected by the US Bureau of the Census concerning housing in the area of Boston, Massachusetts. The dataset includes data on 506 census housing tracts in the Boston area in 1970s.</p>
<p>The <strong>goal</strong> is to predict the median house price in new tracts based on information such as crime rate, pollution, and number of rooms.</p>
<p>The <span style="color:darkred;">response</span> is the median value of owner-occupied homes in $1000s, contained in the column <code>MEDV</code>.</p>
</section>
<section id="the-predictors" class="slide level2">
<h2>The predictors</h2>
<div style="font-size: 70%;">
<ul>
<li><code>CRIM</code>: per capita crime rate by town.</li>
<li><code>ZN</code>: proportion of residential land zoned for lots over 25,000 sq.ft.</li>
<li><code>INDUS</code>: proportion of non-retail business acres per town.</li>
<li><code>CHAS</code>: Charles River (‘Yes’ if tract bounds river; ‘No’ otherwise).</li>
<li><code>NOX</code>: nitrogen oxides concentration (parts per 10 million).</li>
<li><code>RM</code>: average number of rooms per dwelling.</li>
<li><code>AGE</code>: proportion of owner-occupied units built prior to 1940.</li>
<li><code>DIS</code>: weighted mean of distances to five Boston employment centers</li>
<li><code>RAD</code>: index of accessibility to radial highways (‘Low’, ‘Medium’, ‘High’).</li>
<li><code>TAX</code>: full-value property-tax rate per $10,000.</li>
<li><code>PTRATIO</code>: pupil-teacher ratio by town.</li>
<li><code>LSTAT</code>: lower status of the population (percent).</li>
</ul>
</div>
</section>
<section id="read-the-dataset-1" class="slide level2">
<h2>Read the dataset</h2>
<p><br></p>
<p>We read the dataset and set the variable <code>CHAS</code> and <code>RAD</code> as categorical.</p>
<div id="e0ee0c78" class="cell" data-execution_count="13">
<div class="sourceCode cell-code" id="cb12"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb12-1"><a></a>Boston_data <span class="op">=</span> pd.read_excel(<span class="st">'BostonHousing.xlsx'</span>)</span>
<span id="cb12-2"><a></a></span>
<span id="cb12-3"><a></a>Boston_data[<span class="st">'CHAS'</span>] <span class="op">=</span> pd.Categorical(Boston_data[<span class="st">'CHAS'</span>])</span>
<span id="cb12-4"><a></a>Boston_data[<span class="st">'RAD'</span>] <span class="op">=</span> pd.Categorical(Boston_data[<span class="st">'RAD'</span>], </span>
<span id="cb12-5"><a></a>                                      categories<span class="op">=</span>[<span class="st">"Low"</span>, <span class="st">"Medium"</span>, <span class="st">"High"</span>], </span>
<span id="cb12-6"><a></a>                                      ordered<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="section-3" class="slide level2">
<h2></h2>
<p><br><br></p>
<div id="976c8faf" class="cell" data-execution_count="14">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a></a>Boston_data.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="14">
<div>
<style scoped="">
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>

<table class="dataframe caption-top" data-quarto-postprocess="true" data-border="1">
<thead>
<tr class="header" style="text-align: right;">
<th data-quarto-table-cell-role="th"></th>
<th data-quarto-table-cell-role="th">CRIM</th>
<th data-quarto-table-cell-role="th">ZN</th>
<th data-quarto-table-cell-role="th">INDUS</th>
<th data-quarto-table-cell-role="th">CHAS</th>
<th data-quarto-table-cell-role="th">NOX</th>
<th data-quarto-table-cell-role="th">RM</th>
<th data-quarto-table-cell-role="th">AGE</th>
<th data-quarto-table-cell-role="th">DIS</th>
<th data-quarto-table-cell-role="th">RAD</th>
<th data-quarto-table-cell-role="th">TAX</th>
<th data-quarto-table-cell-role="th">PTRATIO</th>
<th data-quarto-table-cell-role="th">LSTAT</th>
<th data-quarto-table-cell-role="th">MEDV</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td data-quarto-table-cell-role="th">0</td>
<td>0.00632</td>
<td>18.0</td>
<td>2.31</td>
<td>No</td>
<td>0.538</td>
<td>6.575</td>
<td>65.2</td>
<td>4.0900</td>
<td>Low</td>
<td>296</td>
<td>15.3</td>
<td>4.98</td>
<td>24.0</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">1</td>
<td>0.02731</td>
<td>0.0</td>
<td>7.07</td>
<td>No</td>
<td>0.469</td>
<td>6.421</td>
<td>78.9</td>
<td>4.9671</td>
<td>Low</td>
<td>242</td>
<td>17.8</td>
<td>9.14</td>
<td>21.6</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">2</td>
<td>0.02729</td>
<td>0.0</td>
<td>7.07</td>
<td>No</td>
<td>0.469</td>
<td>7.185</td>
<td>61.1</td>
<td>4.9671</td>
<td>Low</td>
<td>242</td>
<td>17.8</td>
<td>4.03</td>
<td>34.7</td>
</tr>
<tr class="even">
<td data-quarto-table-cell-role="th">3</td>
<td>0.03237</td>
<td>0.0</td>
<td>2.18</td>
<td>No</td>
<td>0.458</td>
<td>6.998</td>
<td>45.8</td>
<td>6.0622</td>
<td>Low</td>
<td>222</td>
<td>18.7</td>
<td>2.94</td>
<td>33.4</td>
</tr>
<tr class="odd">
<td data-quarto-table-cell-role="th">4</td>
<td>0.06905</td>
<td>0.0</td>
<td>2.18</td>
<td>No</td>
<td>0.458</td>
<td>7.147</td>
<td>54.2</td>
<td>6.0622</td>
<td>Low</td>
<td>222</td>
<td>18.7</td>
<td>5.33</td>
<td>36.2</td>
</tr>
</tbody>
</table>

</div>
</div>
</div>
</section>
<section id="generating-predictors-in-python" class="slide level2">
<h2>Generating predictors in Python</h2>
<p>We use the function <code>.drop()</code> from <strong>pandas</strong> to drop the response column <code>MEDV</code> and store the result in <code>X_full</code>.</p>
<div id="c034417e" class="cell" data-execution_count="15">
<div class="sourceCode cell-code" id="cb14"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb14-1"><a></a><span class="co"># Set full matrix of predictors.</span></span>
<span id="cb14-2"><a></a>X_full <span class="op">=</span> Boston_data.drop(columns <span class="op">=</span> [<span class="st">'MEDV'</span>]) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>Unfortunately, bagging does not work with categorical predictors such as <code>CHAS</code> and <code>RAD</code>. So, we must transform them into dummy variables using the code below.</p>
<div id="bbff0021" class="cell" data-execution_count="16">
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a></a><span class="co"># Turn categorical predictors into dummy variables.</span></span>
<span id="cb15-2"><a></a>X_dummies <span class="op">=</span> pd.get_dummies(X_full[[<span class="st">'CHAS'</span>, <span class="st">'RAD'</span>]], drop_first <span class="op">=</span> <span class="va">True</span>, dtype <span class="op">=</span> <span class="st">'int'</span>)</span>
<span id="cb15-3"><a></a></span>
<span id="cb15-4"><a></a><span class="co"># Drop original predictors from the dataset.</span></span>
<span id="cb15-5"><a></a>X_other <span class="op">=</span> X_full.drop([<span class="st">'CHAS'</span>, <span class="st">'RAD'</span>], axis<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb15-6"><a></a></span>
<span id="cb15-7"><a></a><span class="co"># Update the predictor matrix.</span></span>
<span id="cb15-8"><a></a>X_full <span class="op">=</span> pd.concat([X_other, X_dummies], axis<span class="op">=</span><span class="dv">1</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="section-4" class="slide level2">
<h2></h2>
<p><br></p>
<p>Next, we use the function <code>.filter()</code> from <strong>pandas</strong> to extract the column <code>MEDV</code> from the data frame. We store the result in <code>Y_full</code>.</p>
<div id="d51a7b15" class="cell" data-execution_count="17">
<div class="sourceCode cell-code" id="cb16"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb16-1"><a></a><span class="co"># Set full matrix of responses.</span></span>
<span id="cb16-2"><a></a>Y_full <span class="op">=</span> Boston_data.<span class="bu">filter</span>([<span class="st">'MEDV'</span>])</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><br></p>
<p>We partition the full dataset into 80% for training and the other 20% for validation.</p>
<div id="ce9d8030" class="cell" data-execution_count="18">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb17-1"><a></a><span class="co"># Split the dataset into training and validation.</span></span>
<span id="cb17-2"><a></a>X_train, X_valid, Y_train, Y_valid <span class="op">=</span> train_test_split(X_full, Y_full, </span>
<span id="cb17-3"><a></a>                                                      test_size <span class="op">=</span> <span class="fl">0.2</span>,</span>
<span id="cb17-4"><a></a>                                                      random_state <span class="op">=</span> <span class="dv">507134</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="bagging-in-python" class="slide level2">
<h2>Bagging in Python</h2>
<p>We define a bagging algorithm for regression using the <code>BaggingRegressor</code> function from <strong>scikit-learn</strong>.</p>
<p>The <code>n_estimators</code> argument is the number of decision trees to generate in bagging. Ideally, it should be high, around 500.</p>
<div id="bd6d5f43" class="cell" data-execution_count="19">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a></a><span class="co"># Set the bagging algorithm.</span></span>
<span id="cb18-2"><a></a>Baggingalgorithm <span class="op">=</span> BaggingRegressor(n_estimators <span class="op">=</span> <span class="dv">500</span>, </span>
<span id="cb18-3"><a></a>                                     random_state <span class="op">=</span> <span class="dv">59227</span>)</span>
<span id="cb18-4"><a></a></span>
<span id="cb18-5"><a></a><span class="co"># Train the bagging algorithm.</span></span>
<span id="cb18-6"><a></a>Baggingalgorithm.fit(X_train, Y_train)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><code>random_state</code> allows us to obtain the same bagging algorithm in different runs of the algorithm.</p>
</section>
<section id="predictions-on-the-validation-data-1" class="slide level2">
<h2>Predictions on the validation data</h2>
<p>To predict the responses on the validation data, we use the function <code>.predict()</code> using the predictor values in the validation dataset contained in <code>X_valid</code>.</p>
<div id="a4a37977" class="cell" data-execution_count="20">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb19-1"><a></a>Y_pred <span class="op">=</span> Baggingalgorithm.predict(X_valid)</span>
<span id="cb19-2"><a></a>Y_pred</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-display" data-execution_count="20">
<pre><code>array([19.6658, 13.7368, 21.1204, 44.2054, 25.0334, 34.5046, 30.0714,
       14.9126, 23.185 , 20.2232, 17.0034, 20.0364, 19.7258,  8.9552,
       24.2136, 29.2074, 21.12  , 20.8784, 25.4168, 18.6084, 22.7604,
       26.452 , 24.025 , 35.9372, 23.5698, 20.2344,  8.3688, 15.9038,
       47.4466, 24.2666, 34.4922, 23.2298, 24.4656, 13.3668, 22.6112,
       12.7678, 27.8812, 19.8882, 22.7836, 18.9106,  9.0864, 24.6914,
       21.9024, 12.3184, 27.1866, 33.0508, 19.436 , 25.7136, 19.4562,
       25.3064, 26.8094, 16.9618, 20.8276, 28.7036, 27.884 , 12.5904,
       23.2554, 38.432 , 20.3296, 22.0288, 17.894 , 15.8226, 13.5456,
       21.0472, 23.069 , 20.6296, 20.5934, 15.8522, 32.7326, 33.4602,
       15.3956, 17.5128, 21.2734, 20.6626, 29.7304, 15.4016, 18.9904,
       19.0864, 32.4364, 21.6208, 22.1254, 20.5334, 23.8114, 21.0438,
       34.0556, 21.5676, 19.8904, 19.025 , 21.4108, 15.335 , 46.5098,
       23.533 ,  8.2252, 14.905 , 25.672 , 16.1982, 22.2198, 45.0716,
       14.5424, 21.2396, 14.9436, 22.3806])</code></pre>
</div>
</div>
</section>
<section id="validation-rmse-1" class="slide level2">
<h2>Validation RMSE</h2>
<p><br><br></p>
<p>We compute the <em>root mean squared error</em> on the validation data using the <code>mse()</code> function.</p>
<div id="1bb2ab06" class="cell" data-execution_count="21">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a></a>mse <span class="op">=</span> mean_squared_error(Y_valid, Y_pred)  <span class="co"># Mean Squared Error (MSE)</span></span>
<span id="cb21-2"><a></a><span class="bu">print</span>(<span class="bu">round</span>(mse<span class="op">**</span>(<span class="dv">1</span><span class="op">/</span><span class="dv">2</span>), <span class="dv">2</span>)) <span class="co"># RMSE</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>4.62</code></pre>
</div>
</div>
</section>
<section id="a-single-deep-tree" class="slide level2">
<h2>A single deep tree</h2>
<p>To compare the bagging, let’s use a single deep tree.</p>
<div id="c87ba646" class="cell" data-execution_count="22">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a></a><span class="co"># We tell Python that we want a classification tree</span></span>
<span id="cb23-2"><a></a>reg_tree <span class="op">=</span> DecisionTreeRegressor(ccp_alpha<span class="op">=</span><span class="fl">0.0</span>,</span>
<span id="cb23-3"><a></a>                                 random_state<span class="op">=</span><span class="dv">507134</span>)</span>
<span id="cb23-4"><a></a></span>
<span id="cb23-5"><a></a><span class="co"># We train the classification tree using the training data.</span></span>
<span id="cb23-6"><a></a>reg_tree.fit(X_train, Y_train)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p>And compute the validation RMSE of that tree.</p>
<div id="4dc2ddca" class="cell" data-execution_count="23">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb24-1"><a></a>reg_tree_Y_pred <span class="op">=</span> reg_tree.predict(X_valid)</span>
<span id="cb24-2"><a></a>mse <span class="op">=</span> mean_squared_error(Y_valid, reg_tree_Y_pred) </span>
<span id="cb24-3"><a></a><span class="bu">print</span>(<span class="bu">round</span>(mse<span class="op">**</span>(<span class="dv">1</span><span class="op">/</span><span class="dv">2</span>), <span class="dv">2</span>)) </span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>5.87</code></pre>
</div>
</div>
<p>The validation RMSE of the tree is higher than that of the bagging algorithm. So, ensembeling several trees improves the prediction performance.</p>
</section>
<section id="advantages" class="slide level2">
<h2>Advantages</h2>
<p><br><br></p>
<ul>
<li><p>Bagging will have lower prediction errors than a single regression tree.</p></li>
<li><p>The fact that, for each tree, not all of the original observations were used, can be exploited to produce an estimate of the accuracy for classification. This estimate is called the <u>out-of-bag error</u> estimate which is an estimate of the RMSE on the test dataset.</p></li>
</ul>
</section>
<section id="limitations" class="slide level2">
<h2>Limitations</h2>
<p><br></p>
<ul>
<li><p><em>Loss of interpretability</em>: the final bagged classifier is <span style="color:darkred;">not a tree</span>, and so we forfeit the clear interpretative ability of a classification tree.</p></li>
<li><p><em>Computational complexity</em>: we are essentially multiplying the work of growing (and possibly pruning) a single tree by <span class="math inline">\(B\)</span>.</p></li>
<li><p><em>Fundamental issue</em>: bagging a good model can improve predictive performance, but bagging a bad one can seriously degrade it.</p></li>
</ul>
</section>
<section id="section-5" class="slide level2">
<h2></h2>
<ul>
<li>Bagging is unable to capture simple decision boundaries</li>
</ul>

<img data-src="images/bagging_decision_boundary.png" class="quarto-figure quarto-figure-center r-stretch"></section>
<section id="other-issues" class="slide level2">
<h2>Other issues</h2>
<p><br><br></p>
<ul>
<li><p>Suppose a variable is very important and decisive.</p>
<ul>
<li><p>It will probably appear near the top of a large number of trees.</p></li>
<li><p>And these trees will tend to vote the same way.</p></li>
<li><p>In some sense, then, many of the trees are “correlated”.</p></li>
<li><p>This will degrade the performance of bagging.</p></li>
</ul></li>
</ul>
</section></section>
<section>
<section id="random-forest" class="title-slide slide level1 center">
<h1>Random Forest</h1>

</section>
<section id="random-forest-1" class="slide level2">
<h2>Random Forest</h2>
<p><br></p>
<p>Exactly as bagging, but…</p>
<ul>
<li>When splitting the nodes using the CART algorithm, instead of going through all possible splits for all possible variables, we go through all possible splits on a <span style="color:brown;"><em>random sample of a small number of variables</em> <span class="math inline">\(m\)</span></span>, where <span class="math inline">\(m &lt; p\)</span>.</li>
</ul>
<p>Random forests can improve the performance of bagging.</p>
</section>
<section id="why-does-it-work" class="slide level2">
<h2>Why does it work?</h2>
<p><br></p>
<ul>
<li><p>Not so dominant predictors will get a chance to appear by themselves and show “their stuff”.</p></li>
<li><p>This adds more diversity to the trees.</p></li>
<li><p>The fact that the trees in the forest are not (strongly) correlated means lower variability in the predictions and so, a bettter performance overall.</p></li>
</ul>
</section>
<section id="tuning-parameter" class="slide level2">
<h2>Tuning parameter</h2>
<p><br></p>
<p>How do we set <span class="math inline">\(m\)</span>?</p>
<ul>
<li>For regression, can use <span class="math inline">\(m = \sqrt{p}\)</span> and a minimum leaf node size of 5.</li>
</ul>
<p>In practice, sometimes the best values for these parameters will depend on the problem. So, we can treat <span class="math inline">\(m\)</span> as a tuning parameter.</p>
<blockquote>
<p>Note that if <span class="math inline">\(m = p\)</span>, we get bagging.</p>
</blockquote>
</section>
<section id="the-final-product-is-a-black-box" class="slide level2">
<h2>The final product is a black box</h2>

<img data-src="images/clipboard-2376484681.png" class="quarto-figure quarto-figure-center r-stretch"><ul>
<li><p>A black box. Inside the box are several hundred trees, each slightly different.</p></li>
<li><p>You put an observation into the black box, and the black box classifies it or predicts it for you.</p></li>
</ul>
</section>
<section id="random-forest-in-python" class="slide level2">
<h2>Random Forest in Python</h2>
<p>In Python, we define a RandomForest algorithm for classification using the <code>RandomForestRegressor</code> function from <strong>scikit-learn</strong>.</p>
<div id="e7162d81" class="cell" data-execution_count="24">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb26-1"><a></a><span class="co"># Set the random forest algorithm.</span></span>
<span id="cb26-2"><a></a>RFalgorithm <span class="op">=</span> RandomForestRegressor(n_estimators <span class="op">=</span> <span class="dv">500</span>,</span>
<span id="cb26-3"><a></a>                                    min_samples_leaf <span class="op">=</span> <span class="dv">5</span>,</span>
<span id="cb26-4"><a></a>                                    max_features <span class="op">=</span> <span class="st">"sqrt"</span>,</span>
<span id="cb26-5"><a></a>                                    random_state <span class="op">=</span> <span class="dv">59227</span>)</span>
<span id="cb26-6"><a></a></span>
<span id="cb26-7"><a></a><span class="co"># Train the random forest algorithm.</span></span>
<span id="cb26-8"><a></a>RFalgorithm.fit(X_train, Y_train)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div style="font-size: 90%;">
<p><code>n_estimators</code> sets the number of decision trees to use, <code>min_samples_leaf</code> sets the minimum size for the terminal nodes, and <code>max_features</code> sets the maximum number of predictors to try in each split.</p>
</div>
</section>
<section id="validation-rmse-2" class="slide level2">
<h2>Validation RMSE</h2>
<p><br><br></p>
<p>Evaluate the performance of random forest.</p>
<div id="f372cd17" class="cell" data-execution_count="25">
<div class="sourceCode cell-code" id="cb27"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb27-1"><a></a><span class="co"># Predict responses in validation data.</span></span>
<span id="cb27-2"><a></a>RF_predicted <span class="op">=</span> RFalgorithm.predict(X_valid)</span>
<span id="cb27-3"><a></a></span>
<span id="cb27-4"><a></a><span class="co"># Compute RMSE.</span></span>
<span id="cb27-5"><a></a>mse <span class="op">=</span> mean_squared_error(Y_valid, RF_predicted) </span>
<span id="cb27-6"><a></a><span class="bu">print</span>(<span class="bu">round</span>(mse<span class="op">**</span>(<span class="dv">1</span><span class="op">/</span><span class="dv">2</span>), <span class="dv">2</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>4.63</code></pre>
</div>
</div>
</section>
<section id="predictor-importance" class="slide level2">
<h2>Predictor importance</h2>
<p><br><br></p>
<ul>
<li><p>Random Forests and bagged trees are a black box. But “Importance” is a statistic that attempts to give us some insight.</p></li>
<li><p>The importance statistic assumes that we have trained a random forest and we have validation data.</p></li>
</ul>
</section>
<section id="calculation-of-importance" class="slide level2">
<h2>Calculation of importance</h2>
<p><br></p>
<div>
<ol type="1">
<li class="fragment"><p>We record the prediction error of the trained algorithm on the validation data. This serves as a baseline.</p></li>
<li class="fragment"><p>Next, a variable is “taken out” by having all of its values permuted in the validation dataset. We then compute the prediction error of the algorithm on the perturbed validation data.</p></li>
<li class="fragment"><p>The importance statistic is the difference between the error due to the perturbation and the baseline. A larger difference means an important predictor for the algorithm.</p></li>
</ol>
</div>
</section>
<section id="section-6" class="slide level2">
<h2></h2>
<p><br><br><br></p>
<p>In Python, we use compute the predictor importance using the <code>permutation_importance()</code> function.</p>
<div id="8c8a9d7b" class="cell" data-execution_count="26">
<div class="sourceCode cell-code" id="cb29"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb29-1"><a></a><span class="co"># Compute permutation importance</span></span>
<span id="cb29-2"><a></a>result <span class="op">=</span> permutation_importance(RFalgorithm, X_valid, Y_valid,</span>
<span id="cb29-3"><a></a>                                n_repeats<span class="op">=</span><span class="dv">5</span>, random_state<span class="op">=</span><span class="dv">59227</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="section-7" class="slide level2">
<h2></h2>
<p><br></p>
<div id="b68c8923" class="cell" data-execution_count="27">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb30-1"><a></a><span class="co"># Create DataFrame</span></span>
<span id="cb30-2"><a></a>importance_df <span class="op">=</span> pd.DataFrame({</span>
<span id="cb30-3"><a></a>    <span class="st">'Feature'</span>: X_valid.columns,</span>
<span id="cb30-4"><a></a>    <span class="st">'Importance'</span>: result.importances_mean</span>
<span id="cb30-5"><a></a>}).sort_values(by<span class="op">=</span><span class="st">'Importance'</span>, ascending<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb30-6"><a></a></span>
<span id="cb30-7"><a></a><span class="co"># Plot bar chart</span></span>
<span id="cb30-8"><a></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">8</span>, <span class="dv">5</span>))</span>
<span id="cb30-9"><a></a>plt.bar(importance_df[<span class="st">'Feature'</span>], importance_df[<span class="st">'Importance'</span>])</span>
<span id="cb30-10"><a></a>plt.xticks(rotation<span class="op">=</span><span class="dv">90</span>)</span>
<span id="cb30-11"><a></a>plt.title(<span class="st">'Permutation Feature Importance'</span>)</span>
<span id="cb30-12"><a></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="Nonparametric_files/figure-revealjs/cell-28-output-1.png" class="quarto-figure quarto-figure-center" width="656" height="512"></p>
</figure>
</div>
</div>
</div>
</section></section>
<section>
<section id="boosting" class="title-slide slide level1 center">
<h1>Boosting</h1>

</section>
<section id="boosting-1" class="slide level2">
<h2>Boosting</h2>
<p><br><br></p>
<ul>
<li><p>In boosting, we also grow multiple decision trees. But instead of growing trees randomly, each new tree depends on the previous one.</p></li>
<li><p>Boosting is easier to understand in the context of regression, rather than classification.</p></li>
<li><p><u>Idea</u>: Explore <span style="color:brown;"><strong>cooperation</strong></span> between desicion trees, rather than <span style="color:#4682B4;">diversity</span> as in Bagging and Random Forest.</p></li>
</ul>
</section>
<section id="boosting-for-regression" class="slide level2">
<h2>Boosting for regression</h2>
<ul>
<li><p>Boosting creates a sequence of trees, each one building upon the previous.</p></li>
<li><p>Earlier trees are small, and the next tree is created with the <strong>residuals</strong> of the previous tree.</p></li>
<li><p>In other words, at each step, we try to explain the information that we didn’t explain in previous steps.</p></li>
<li><p>Gradually, the sequence “learns” to predict.</p></li>
<li><p>Something a little odd: earlier trees are deliberately “held back” to keep them from explaining too much. This creates “slow learning”.</p></li>
</ul>
</section>
<section id="section-8" class="slide level2">
<h2></h2>

<img data-src="images/clipboard-720176022.png" class="quarto-figure quarto-figure-center r-stretch"><p><a href="https://pythongeeks.org/gradient-boosting-algorithm-in-machine-learning/" class="uri">https://pythongeeks.org/gradient-boosting-algorithm-in-machine-learning/</a></p>
</section>
<section id="section-9" class="slide level2">
<h2></h2>
<div style="font-size: 95%;">
<p>Initially, the boosted tree is <span class="math inline">\(\hat{f}(\boldsymbol{x}) = 0\)</span> and the residuals of this tree are <span class="math inline">\(r_i = y_i - f(\boldsymbol{x}_i)\)</span> for all <span class="math inline">\(i\)</span> in the training data.</p>
<p>At each step <span class="math inline">\(b\)</span> in the process (<span class="math inline">\(b = 1, \ldots, B\)</span>), we</p>
<ol type="1">
<li><strong>Build</strong> a regression tree <span class="math inline">\(\hat{T}_b\)</span> with <span class="math inline">\(d\)</span> splits to the training data <span class="math inline">\((\boldsymbol{X}, \boldsymbol{r})\)</span>. This tree has <span class="math inline">\(d+1\)</span> terminal nodes.</li>
<li><strong>Update</strong> the boosted tree <span class="math inline">\(\hat{f}\)</span> by adding in a <span style="color:orange;"><strong><em>shrunken version</em></strong></span> of the new tree: <span class="math inline">\(\hat{f}(\boldsymbol{x}) \leftarrow \hat{f}(\boldsymbol{x}) + \lambda \hat{T}_b(\boldsymbol{x})\)</span>.</li>
<li><strong>Update</strong> the residuals using shrunken tree, <span class="math inline">\(r_i \leftarrow r_i - \lambda \hat{T}_b(x_i)\)</span>.</li>
</ol>
<p>The final boosted tree is: <span class="math inline">\(\hat{f}(\boldsymbol{x}) = \sum_{b=1}^{B} \lambda \hat{T}_b (\boldsymbol{x}).\)</span></p>
</div>
<aside class="notes">
<p>D is 4 or 5, sometimes 1. Lambda is 0.001 or 0.01 This algorithm is a gradient boosting method for regression.</p>
<style type="text/css">
        span.MJX_Assistive_MathML {
          position:absolute!important;
          clip: rect(1px, 1px, 1px, 1px);
          padding: 1px 0 0 0!important;
          border: 0!important;
          height: 1px!important;
          width: 1px!important;
          overflow: hidden!important;
          display:block!important;
      }</style></aside>
</section>
<section id="why-does-this-work" class="slide level2">
<h2>Why does this work?</h2>
<div style="font-size: 90%;">
<ul>
<li><p>By using a small tree, we are deliberately leaving information out of the first round of the model. So what gets fit is the “easy” stuff.</p></li>
<li><p>The residuals have all of the information that we haven’t yet explained. We continue iterating on the residuals, fitting them with small trees, so that we slowly explain the bits of the variation that are harder to explain.</p></li>
<li><p>This process is called “learning”: at each iteration, we get a better fit.</p></li>
<li><p>By multiplying by <span class="math inline">\(\lambda &lt;1\)</span>, we “slow down” the learning (by making it harder to fit all of the variation), and there is research that says that slower learning is better.</p></li>
</ul>
</div>
</section>
<section id="tuning-parameters" class="slide level2">
<h2>Tuning parameters</h2>
<p><br><br></p>
<p>The <span style="color:brown;"><strong>number of trees</strong></span> <span class="math inline">\(B\)</span>. Unlike bagging and random forest, boosting can overfit if <span class="math inline">\(B\)</span> is too large. We use so-called <em>K-fold cross-validation</em> to select <span class="math inline">\(B\)</span>.</p>
<p>The <span style="color:brown;"><strong>shrinkage parameter</strong></span> <span class="math inline">\(\lambda\)</span>, a small positive number. Typical values are 0.01 or 0.001. Very small <span class="math inline">\(\lambda\)</span> can require using a very large value of B to achieve good performance.</p>
<p>The <span style="color:brown;"><strong>number of splits</strong></span> <span class="math inline">\(d\)</span> in each tree. Common choices are 1, 4 or 5. Often <span class="math inline">\(d = 1\)</span>, in which case each tree is a stump.</p>
</section>
<section id="boosting-in-python" class="slide level2">
<h2>Boosting in Python</h2>
<p>In Python, we define a Boosting algorithm for classification using the <code>GradientBoostingRegressor</code> function from <strong>scikit-learn</strong>.</p>
<div id="a1132693" class="cell" data-execution_count="28">
<div class="sourceCode cell-code" id="cb31"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb31-1"><a></a><span class="co"># Set the boosting algorithm.</span></span>
<span id="cb31-2"><a></a>GBalgorithm <span class="op">=</span> GradientBoostingRegressor(learning_rate <span class="op">=</span> <span class="fl">0.1</span>,</span>
<span id="cb31-3"><a></a>                                    n_estimators <span class="op">=</span> <span class="dv">1000</span>,</span>
<span id="cb31-4"><a></a>                                    max_depth <span class="op">=</span> <span class="dv">3</span>,</span>
<span id="cb31-5"><a></a>                                    random_state <span class="op">=</span> <span class="dv">59227</span>)</span>
<span id="cb31-6"><a></a></span>
<span id="cb31-7"><a></a><span class="co"># Train the boosting algorithm.</span></span>
<span id="cb31-8"><a></a>GBalgorithm.fit(X_train, Y_train)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<p><code>n_estimators</code> sets the number of decision trees to use, <code>learning_rate</code> sets the value of <span class="math inline">\(\lambda\)</span>, and <code>max_depth</code> sets the depth of the tree.</p>
</section>
<section id="validation-rmse-for-boosting" class="slide level2">
<h2>Validation RMSE for boosting</h2>
<p><br><br></p>
<p>Evaluate the performance of the boosting algorithm.</p>
<div id="24a5c326" class="cell" data-execution_count="29">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a></a><span class="co"># Predict responses in validation data.</span></span>
<span id="cb32-2"><a></a>GB_predicted <span class="op">=</span> GBalgorithm.predict(X_valid)</span>
<span id="cb32-3"><a></a></span>
<span id="cb32-4"><a></a><span class="co"># Compute RMSE.</span></span>
<span id="cb32-5"><a></a>mse <span class="op">=</span> mean_squared_error(Y_valid, GB_predicted) </span>
<span id="cb32-6"><a></a><span class="bu">print</span>(<span class="bu">round</span>(mse<span class="op">**</span>(<span class="dv">1</span><span class="op">/</span><span class="dv">2</span>), <span class="dv">2</span>))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>3.85</code></pre>
</div>
</div>
</section>
<section id="predictor-importance-1" class="slide level2">
<h2>Predictor importance</h2>
<p>We can also apply predictor importance to the gradient boosting algorithm.</p>
<div id="0713821e" class="cell" data-execution_count="30">
<details class="code-fold">
<summary>Code</summary>
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode numberSource python number-lines code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a></a><span class="co"># Compute permutation importance</span></span>
<span id="cb34-2"><a></a>result <span class="op">=</span> permutation_importance(GBalgorithm, X_valid, Y_valid, n_repeats<span class="op">=</span><span class="dv">5</span>, random_state<span class="op">=</span><span class="dv">59227</span>)</span>
<span id="cb34-3"><a></a><span class="co"># Create DataFrame</span></span>
<span id="cb34-4"><a></a>importance_df <span class="op">=</span> pd.DataFrame({</span>
<span id="cb34-5"><a></a>    <span class="st">'Feature'</span>: X_valid.columns,</span>
<span id="cb34-6"><a></a>    <span class="st">'Importance'</span>: result.importances_mean</span>
<span id="cb34-7"><a></a>}).sort_values(by<span class="op">=</span><span class="st">'Importance'</span>, ascending<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb34-8"><a></a></span>
<span id="cb34-9"><a></a><span class="co"># Plot bar chart</span></span>
<span id="cb34-10"><a></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">5</span>, <span class="dv">3</span>))</span>
<span id="cb34-11"><a></a>plt.bar(importance_df[<span class="st">'Feature'</span>], importance_df[<span class="st">'Importance'</span>])</span>
<span id="cb34-12"><a></a>plt.xticks(rotation<span class="op">=</span><span class="dv">90</span>)</span>
<span id="cb34-13"><a></a>plt.title(<span class="st">'Permutation Feature Importance'</span>)</span>
<span id="cb34-14"><a></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</details>
<div class="cell-output cell-output-display">
<div class="quarto-figure quarto-figure-center">
<figure>
<p><img data-src="Nonparametric_files/figure-revealjs/cell-31-output-1.png" class="quarto-figure quarto-figure-center" width="424" height="365"></p>
</figure>
</div>
</div>
</div>
</section>
<section id="issues-with-boosting" class="slide level2">
<h2>Issues with boosting</h2>
<p><br><br></p>
<ul>
<li><p>Loss of interpretability: the final boosted model is a weighted sum of trees, which we cannot interpret easily.</p></li>
<li><p>Computational complexity: since it uses slow learners, it can be time consuming. However, we are growing small trees, each step can be done relatively quickly in some cases (e.g.&nbsp;AdaBoost).</p></li>
</ul>
</section></section>
<section>
<section id="ensemble-methods-for-time-series" class="title-slide slide level1 center">
<h1>Ensemble methods for Time Series</h1>

</section>
<section id="example-3" class="slide level2">
<h2>Example 3</h2>
<p>Let’s consider the dataset consisting of weekly cases of chickenpox (a childhood disease) in Hungary. The dataset has the number of reported cases in Budapest from January 2005 to December 2013.</p>
<p>The goal is to predict the number of reported cases weekly starting in 2014.</p>
</section></section>
<section id="return-to-main-page" class="title-slide slide level1 center">
<h1><a href="https://alanrvazquez.github.io/TEC-IN2004B/">Return to main page</a></h1>


</section>
    </div>
  <div class="quarto-auto-generated-content" style="display: none;">
<p><img src="IN2004B_logo.png" class="slide-logo"></p>
<div class="footer footer-default">
<p>Tecnologico de Monterrey</p>
</div>
</div></div>

  <script>window.backupDefine = window.define; window.define = undefined;</script>
  <script src="../site_libs/revealjs/dist/reveal.js"></script>
  <!-- reveal.js plugins -->
  <script src="../site_libs/revealjs/plugin/quarto-line-highlight/line-highlight.js"></script>
  <script src="../site_libs/revealjs/plugin/pdf-export/pdfexport.js"></script>
  <script src="../site_libs/revealjs/plugin/reveal-menu/menu.js"></script>
  <script src="../site_libs/revealjs/plugin/reveal-menu/quarto-menu.js"></script>
  <script src="../site_libs/revealjs/plugin/quarto-support/support.js"></script>
  

  <script src="../site_libs/revealjs/plugin/notes/notes.js"></script>
  <script src="../site_libs/revealjs/plugin/search/search.js"></script>
  <script src="../site_libs/revealjs/plugin/zoom/zoom.js"></script>
  <script src="../site_libs/revealjs/plugin/math/math.js"></script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script>

  <script>

      // Full list of configuration options available at:
      // https://revealjs.com/config/
      Reveal.initialize({
'controlsAuto': true,
'previewLinksAuto': false,
'pdfSeparateFragments': false,
'autoAnimateEasing': "ease",
'autoAnimateDuration': 1,
'autoAnimateUnmatched': true,
'jumpToSlide': true,
'menu': {"side":"left","useTextContentForMissingTitles":true,"markers":false,"loadIcons":false,"custom":[{"title":"Tools","icon":"<i class=\"fas fa-gear\"></i>","content":"<ul class=\"slide-menu-items\">\n<li class=\"slide-tool-item active\" data-item=\"0\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.fullscreen(event)\"><kbd>f</kbd> Fullscreen</a></li>\n<li class=\"slide-tool-item\" data-item=\"1\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.speakerMode(event)\"><kbd>s</kbd> Speaker View</a></li>\n<li class=\"slide-tool-item\" data-item=\"2\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.overview(event)\"><kbd>o</kbd> Slide Overview</a></li>\n<li class=\"slide-tool-item\" data-item=\"3\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.togglePdfExport(event)\"><kbd>e</kbd> PDF Export Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"4\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.toggleScrollView(event)\"><kbd>r</kbd> Scroll View Mode</a></li>\n<li class=\"slide-tool-item\" data-item=\"5\"><a href=\"#\" onclick=\"RevealMenuToolHandlers.keyboardHelp(event)\"><kbd>?</kbd> Keyboard Help</a></li>\n</ul>"}],"openButton":true},
'smaller': false,
 
        // Display controls in the bottom right corner
        controls: false,

        // Help the user learn the controls by providing hints, for example by
        // bouncing the down arrow when they first encounter a vertical slide
        controlsTutorial: false,

        // Determines where controls appear, "edges" or "bottom-right"
        controlsLayout: 'edges',

        // Visibility rule for backwards navigation arrows; "faded", "hidden"
        // or "visible"
        controlsBackArrows: 'faded',

        // Display a presentation progress bar
        progress: true,

        // Display the page number of the current slide
        slideNumber: 'c/t',

        // 'all', 'print', or 'speaker'
        showSlideNumber: 'all',

        // Add the current slide number to the URL hash so that reloading the
        // page/copying the URL will return you to the same slide
        hash: true,

        // Start with 1 for the hash rather than 0
        hashOneBasedIndex: false,

        // Flags if we should monitor the hash and change slides accordingly
        respondToHashChanges: true,

        // Push each slide change to the browser history
        history: true,

        // Enable keyboard shortcuts for navigation
        keyboard: true,

        // Enable the slide overview mode
        overview: true,

        // Disables the default reveal.js slide layout (scaling and centering)
        // so that you can use custom CSS layout
        disableLayout: false,

        // Vertical centering of slides
        center: false,

        // Enables touch navigation on devices with touch input
        touch: true,

        // Loop the presentation
        loop: false,

        // Change the presentation direction to be RTL
        rtl: false,

        // see https://revealjs.com/vertical-slides/#navigation-mode
        navigationMode: 'linear',

        // Randomizes the order of slides each time the presentation loads
        shuffle: false,

        // Turns fragments on and off globally
        fragments: true,

        // Flags whether to include the current fragment in the URL,
        // so that reloading brings you to the same fragment position
        fragmentInURL: false,

        // Flags if the presentation is running in an embedded mode,
        // i.e. contained within a limited portion of the screen
        embedded: false,

        // Flags if we should show a help overlay when the questionmark
        // key is pressed
        help: true,

        // Flags if it should be possible to pause the presentation (blackout)
        pause: true,

        // Flags if speaker notes should be visible to all viewers
        showNotes: false,

        // Global override for autoplaying embedded media (null/true/false)
        autoPlayMedia: null,

        // Global override for preloading lazy-loaded iframes (null/true/false)
        preloadIframes: null,

        // Number of milliseconds between automatically proceeding to the
        // next slide, disabled when set to 0, this value can be overwritten
        // by using a data-autoslide attribute on your slides
        autoSlide: 0,

        // Stop auto-sliding after user input
        autoSlideStoppable: true,

        // Use this method for navigation when auto-sliding
        autoSlideMethod: null,

        // Specify the average time in seconds that you think you will spend
        // presenting each slide. This is used to show a pacing timer in the
        // speaker view
        defaultTiming: null,

        // Enable slide navigation via mouse wheel
        mouseWheel: false,

        // The display mode that will be used to show slides
        display: 'block',

        // Hide cursor if inactive
        hideInactiveCursor: true,

        // Time before the cursor is hidden (in ms)
        hideCursorTime: 5000,

        // Opens links in an iframe preview overlay
        previewLinks: false,

        // Transition style (none/fade/slide/convex/concave/zoom)
        transition: 'none',

        // Transition speed (default/fast/slow)
        transitionSpeed: 'default',

        // Transition style for full page slide backgrounds
        // (none/fade/slide/convex/concave/zoom)
        backgroundTransition: 'none',

        // Number of slides away from the current that are visible
        viewDistance: 3,

        // Number of slides away from the current that are visible on mobile
        // devices. It is advisable to set this to a lower number than
        // viewDistance in order to save resources.
        mobileViewDistance: 2,

        // The "normal" size of the presentation, aspect ratio will be preserved
        // when the presentation is scaled to fit different resolutions. Can be
        // specified using percentage units.
        width: 1050,

        height: 700,

        // Factor of the display size that should remain empty around the content
        margin: 0.1,

        math: {
          mathjax: 'https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js',
          config: 'TeX-AMS_HTML-full',
          tex2jax: {
            inlineMath: [['\\(','\\)']],
            displayMath: [['\\[','\\]']],
            balanceBraces: true,
            processEscapes: false,
            processRefs: true,
            processEnvironments: true,
            preview: 'TeX',
            skipTags: ['script','noscript','style','textarea','pre','code'],
            ignoreClass: 'tex2jax_ignore',
            processClass: 'tex2jax_process'
          },
        },

        // reveal.js plugins
        plugins: [QuartoLineHighlight, PdfExport, RevealMenu, QuartoSupport,

          RevealMath,
          RevealNotes,
          RevealSearch,
          RevealZoom
        ]
      });
    </script>
    <script id="quarto-html-after-body" type="application/javascript">
    window.document.addEventListener("DOMContentLoaded", function (event) {
      const toggleBodyColorMode = (bsSheetEl) => {
        const mode = bsSheetEl.getAttribute("data-mode");
        const bodyEl = window.document.querySelector("body");
        if (mode === "dark") {
          bodyEl.classList.add("quarto-dark");
          bodyEl.classList.remove("quarto-light");
        } else {
          bodyEl.classList.add("quarto-light");
          bodyEl.classList.remove("quarto-dark");
        }
      }
      const toggleBodyColorPrimary = () => {
        const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
        if (bsSheetEl) {
          toggleBodyColorMode(bsSheetEl);
        }
      }
      toggleBodyColorPrimary();  
      const tabsets =  window.document.querySelectorAll(".panel-tabset-tabby")
      tabsets.forEach(function(tabset) {
        const tabby = new Tabby('#' + tabset.id);
      });
      const isCodeAnnotation = (el) => {
        for (const clz of el.classList) {
          if (clz.startsWith('code-annotation-')) {                     
            return true;
          }
        }
        return false;
      }
      const onCopySuccess = function(e) {
        // button target
        const button = e.trigger;
        // don't keep focus
        button.blur();
        // flash "checked"
        button.classList.add('code-copy-button-checked');
        var currentTitle = button.getAttribute("title");
        button.setAttribute("title", "Copied!");
        let tooltip;
        if (window.bootstrap) {
          button.setAttribute("data-bs-toggle", "tooltip");
          button.setAttribute("data-bs-placement", "left");
          button.setAttribute("data-bs-title", "Copied!");
          tooltip = new bootstrap.Tooltip(button, 
            { trigger: "manual", 
              customClass: "code-copy-button-tooltip",
              offset: [0, -8]});
          tooltip.show();    
        }
        setTimeout(function() {
          if (tooltip) {
            tooltip.hide();
            button.removeAttribute("data-bs-title");
            button.removeAttribute("data-bs-toggle");
            button.removeAttribute("data-bs-placement");
          }
          button.setAttribute("title", currentTitle);
          button.classList.remove('code-copy-button-checked');
        }, 1000);
        // clear code selection
        e.clearSelection();
      }
      const getTextToCopy = function(trigger) {
          const codeEl = trigger.previousElementSibling.cloneNode(true);
          for (const childEl of codeEl.children) {
            if (isCodeAnnotation(childEl)) {
              childEl.remove();
            }
          }
          return codeEl.innerText;
      }
      const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
        text: getTextToCopy
      });
      clipboard.on('success', onCopySuccess);
      if (window.document.getElementById('quarto-embedded-source-code-modal')) {
        const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
          text: getTextToCopy,
          container: window.document.getElementById('quarto-embedded-source-code-modal')
        });
        clipboardModal.on('success', onCopySuccess);
      }
        var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
        var mailtoRegex = new RegExp(/^mailto:/);
          var filterRegex = new RegExp('/' + window.location.host + '/');
        var isInternal = (href) => {
            return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
        }
        // Inspect non-navigation links and adorn them if external
     	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
        for (var i=0; i<links.length; i++) {
          const link = links[i];
          if (!isInternal(link.href)) {
            // undo the damage that might have been done by quarto-nav.js in the case of
            // links that we want to consider external
            if (link.dataset.originalHref !== undefined) {
              link.href = link.dataset.originalHref;
            }
          }
        }
      function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
        const config = {
          allowHTML: true,
          maxWidth: 500,
          delay: 100,
          arrow: false,
          appendTo: function(el) {
              return el.closest('section.slide') || el.parentElement;
          },
          interactive: true,
          interactiveBorder: 10,
          theme: 'light-border',
          placement: 'bottom-start',
        };
        if (contentFn) {
          config.content = contentFn;
        }
        if (onTriggerFn) {
          config.onTrigger = onTriggerFn;
        }
        if (onUntriggerFn) {
          config.onUntrigger = onUntriggerFn;
        }
          config['offset'] = [0,0];
          config['maxWidth'] = 700;
        window.tippy(el, config); 
      }
      const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
      for (var i=0; i<noterefs.length; i++) {
        const ref = noterefs[i];
        tippyHover(ref, function() {
          // use id or data attribute instead here
          let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
          try { href = new URL(href).hash; } catch {}
          const id = href.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note) {
            return note.innerHTML;
          } else {
            return "";
          }
        });
      }
      const findCites = (el) => {
        const parentEl = el.parentElement;
        if (parentEl) {
          const cites = parentEl.dataset.cites;
          if (cites) {
            return {
              el,
              cites: cites.split(' ')
            };
          } else {
            return findCites(el.parentElement)
          }
        } else {
          return undefined;
        }
      };
      var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
      for (var i=0; i<bibliorefs.length; i++) {
        const ref = bibliorefs[i];
        const citeInfo = findCites(ref);
        if (citeInfo) {
          tippyHover(citeInfo.el, function() {
            var popup = window.document.createElement('div');
            citeInfo.cites.forEach(function(cite) {
              var citeDiv = window.document.createElement('div');
              citeDiv.classList.add('hanging-indent');
              citeDiv.classList.add('csl-entry');
              var biblioDiv = window.document.getElementById('ref-' + cite);
              if (biblioDiv) {
                citeDiv.innerHTML = biblioDiv.innerHTML;
              }
              popup.appendChild(citeDiv);
            });
            return popup.innerHTML;
          });
        }
      }
    });
    </script>
    

</body></html>